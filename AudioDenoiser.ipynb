{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankit\\Documents\\Audio_assignment\\audenv\\lib\\site-packages\\df\\io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n",
      "c:\\Users\\ankit\\Documents\\Audio_assignment\\audenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary Libraries\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "from df.enhance import enhance, init_df, resample\n",
    "from pyannote.audio import Pipeline\n",
    "import warnings\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for audio streaming\n",
    "CHUNK = 1024  # audio samples per chunk\n",
    "FORMAT = pyaudio.paInt16  # Audio format\n",
    "CHANNELS = 1  # Mono audio for single microphone need to change for multi-microphones but mostly it is single channel\n",
    "RATE = 16000  # Sampling rate in Hz it needs to be resampled in real time\n",
    "LATENCY = 0.1  # Target latency in seconds (100 milisconds)\n",
    "OUTPUT_FILE = \"output_real_time.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DeepFilterNet model\n",
    "model, df_state, _ = init_df()\n",
    "\n",
    "# Initialize Pyannote audio pipeline for speaker diarization\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\"\n",
    ").to(torch.device(\"cpu\")) # use cuda for better & faster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\ankit\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\ankit\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cpu\u001b[0m\n",
      "\u001b[32m2025-01-04 12:15:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Identifying Dominant speaker from multi speakers when the mode is single; so we can \n",
    "# only get the one speaker in multi-speaker scenario\n",
    "def identify_dominant_speaker_by_energy(audio_data, sample_rate):\n",
    "    temp_file = \"temp_audio.wav\" # Saving the live streaming audio data in a temporary file\n",
    "    with wave.open(temp_file, 'wb') as wf:\n",
    "        wf.setnchannels(1) # Setting channel as 1; can do with 2 or 3 based on the microphones or input devices\n",
    "        wf.setsampwidth(2)  # 16-bit audio\n",
    "        wf.setframerate(sample_rate) # saving the frame rate as RATE\n",
    "        wf.writeframes(audio_data.astype(np.int16).tobytes()) # Saving the frames\n",
    "\n",
    "    diarization = pipeline(temp_file) # Diarization\n",
    "    speaker_energies = {} # Finding out argmax speaker energy through the intensity or energy\n",
    "\n",
    "    for segment, _, speaker in diarization.itertracks(yield_label=True): # Iterable through the track\n",
    "        start = int(segment.start * sample_rate)\n",
    "        end = int(segment.end * sample_rate)\n",
    "        segment_energy = np.sum(audio_data[start:end] ** 2) \n",
    "        speaker_energies[speaker] = speaker_energies.get(speaker, 0) + segment_energy\n",
    "\n",
    "    os.remove(temp_file)  # Cleaning up temporary file\n",
    "\n",
    "    if not speaker_energies: # If there is no sound or blank\n",
    "        raise ValueError(\"No speakers detected in the audio stream.\")\n",
    "\n",
    "    dominant_speaker = max(speaker_energies, key=speaker_energies.get)\n",
    "    return dominant_speaker, diarization\n",
    "\n",
    "\n",
    "def real_time_denoising(mode=\"single\"):\n",
    "    \"\"\"Real-time noise cancellation with single or multi-speaker mode.\"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    # Initialzing the stream\n",
    "    stream_in = p.open(\n",
    "        format=FORMAT,\n",
    "        channels=CHANNELS,\n",
    "        rate=RATE,\n",
    "        input=True,\n",
    "        frames_per_buffer=CHUNK\n",
    "    )\n",
    "\n",
    "    print(\"Real-time noise cancellation system started...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    try:\n",
    "        while True: # The stream will go on until execution stopped\n",
    "            data = stream_in.read(CHUNK, exception_on_overflow=False) # taking the data from stream\n",
    "            audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "            # In two modes we have to take single and multi speakers\n",
    "            ## If the mode is single & there are multiple modes we need to eliminate other non-dominant speakers\n",
    "            if mode == \"single\":\n",
    "                try:\n",
    "                    print(\"Applying single-speaker noise cancellation...\")\n",
    "                    dominant_speaker, diarization = identify_dominant_speaker_by_energy(audio_data, RATE)\n",
    "\n",
    "                    retained_audio = np.zeros_like(audio_data)\n",
    "                    for segment, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                        if speaker == dominant_speaker:\n",
    "                            start = int(segment.start * RATE)\n",
    "                            end = int(segment.end * RATE)\n",
    "                            retained_audio[start:end] = audio_data[start:end]\n",
    "\n",
    "                    audio_tensor = resample(\n",
    "                        torch.Tensor(np.array([retained_audio])), RATE, df_state.sr(), method=\"sinc_best\"\n",
    "                    ) # Also can use 'sinc_fast' as well for method\n",
    "                    enhanced_audio = enhance(model, df_state, audio_tensor)\n",
    "                except ValueError as e: # If there are empty chunks or any value errors\n",
    "                    print(f\"Warning: {e}. Skipping this chunk.\")\n",
    "                    continue\n",
    "\n",
    "            ## We only need to remove background noise & all the speakers will be there in the recording\n",
    "            elif mode == \"multi\":\n",
    "                print(\"Applying multi-speaker noise cancellation...\")\n",
    "                audio_tensor = resample(\n",
    "                    torch.Tensor(np.array([audio_data])), RATE, df_state.sr(), method=\"sinc_best\"\n",
    "                ) # Also can use 'sinc_fast' as well for method \n",
    "                enhanced_audio = enhance(model, df_state, audio_tensor)\n",
    "\n",
    "            else: # Choose between 'single' and 'multi'\n",
    "                raise ValueError(\"Invalid mode. Choose 'single' or 'multi'.\")\n",
    "\n",
    "            enhanced_audio_resampled = resample(\n",
    "                enhanced_audio, df_state.sr(), RATE, method=\"sinc_best\"\n",
    "            ).numpy()\n",
    "\n",
    "            frames.append(enhanced_audio_resampled.flatten())\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping real-time noise cancellation...\")\n",
    "    finally:\n",
    "        stream_in.stop_stream()\n",
    "        stream_in.close()\n",
    "        p.terminate()\n",
    "\n",
    "        if frames:\n",
    "            with wave.open(OUTPUT_FILE, 'wb') as wf:\n",
    "                wf.setnchannels(CHANNELS)\n",
    "                wf.setsampwidth(2)  # 16-bit audio\n",
    "                wf.setframerate(RATE)\n",
    "                wf.writeframes(np.concatenate(frames).astype(np.int16).tobytes())\n",
    "\n",
    "            print(f\"Processed audio saved to {OUTPUT_FILE}\")\n",
    "        else: ## If there are no frames no output file will be processed\n",
    "            print(\"No audio processed; output file not created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-time noise cancellation system started...\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Warning: No speakers detected in the audio stream.. Skipping this chunk.\n",
      "Applying single-speaker noise cancellation...\n",
      "Stopping real-time noise cancellation...\n",
      "Processed audio saved to output_real_time.wav\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": ## Start the stream from here\n",
    "    mode = input(\"Enter mode (single/multi): \").strip().lower()\n",
    "    real_time_denoising(mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
